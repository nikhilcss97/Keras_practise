{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eng_to_french.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilcss97/Keras_practise/blob/master/eng_to_french.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0vUwXV8I-JJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "108cef32-18a4-4fcb-db42-1b099f4c7d60"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fra.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sjjX6Yt_R86S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f40dbc4-59a7-4798-901b-2a20248f2038"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM, CuDNNLSTM, Input, Embedding, TimeDistributed, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "import string\n",
        "import operator"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "crCwOtoPR4jF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('fra.txt', sep= '\\t', header=None)\n",
        "data= data.head(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mROGWn3xT5LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lower= lambda x: str.lower(x)\n",
        "data= data.applymap(lower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Skh2rKtxdePS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exclude = set(string.punctuation)\n",
        "rm_punc= lambda s: ''.join(ch for ch in s if ch not in exclude)\n",
        "data= data.applymap(rm_punc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rlml64QLfaGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm_digits = lambda s: ''.join([i for i in s if not i.isdigit()])\n",
        "data= data.applymap(rm_digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snS2mk7DiOV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "5a183ec9-bdfa-49a5-ba41-a2ca73d941f5"
      },
      "cell_type": "code",
      "source": [
        "data.columns= ['en', 'fr']\n",
        "data"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go</td>\n",
              "      <td>va</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>salut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>cours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>courez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wow</td>\n",
              "      <td>ça alors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fire</td>\n",
              "      <td>au feu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>help</td>\n",
              "      <td>à laide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>jump</td>\n",
              "      <td>saute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>stop</td>\n",
              "      <td>ça suffit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>stop</td>\n",
              "      <td>stop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>stop</td>\n",
              "      <td>arrêtetoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>wait</td>\n",
              "      <td>attends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>wait</td>\n",
              "      <td>attendez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>go on</td>\n",
              "      <td>poursuis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>go on</td>\n",
              "      <td>continuez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>go on</td>\n",
              "      <td>poursuivez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>hello</td>\n",
              "      <td>bonjour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>hello</td>\n",
              "      <td>salut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i see</td>\n",
              "      <td>je comprends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>i try</td>\n",
              "      <td>jessaye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>i won</td>\n",
              "      <td>jai gagné</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i won</td>\n",
              "      <td>je lai emporté</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>oh no</td>\n",
              "      <td>oh non</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>attack</td>\n",
              "      <td>attaque</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>attack</td>\n",
              "      <td>attaquez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>cheers</td>\n",
              "      <td>santé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>cheers</td>\n",
              "      <td>à votre santé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>cheers</td>\n",
              "      <td>merci</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>cheers</td>\n",
              "      <td>tchintchin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>get up</td>\n",
              "      <td>lèvetoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4970</th>\n",
              "      <td>how can i pay</td>\n",
              "      <td>comment puisje payer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4971</th>\n",
              "      <td>how can it be</td>\n",
              "      <td>comment se peutil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4972</th>\n",
              "      <td>how can it be</td>\n",
              "      <td>comment cela se peutil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4973</th>\n",
              "      <td>how do i look</td>\n",
              "      <td>de quoi aije lair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>how old is he</td>\n",
              "      <td>quel âge atil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>how thrilling</td>\n",
              "      <td>comme cest excitant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>how thrilling</td>\n",
              "      <td>comme cest palpitant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4977</th>\n",
              "      <td>how was class</td>\n",
              "      <td>comment était lécole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4978</th>\n",
              "      <td>hows the dog</td>\n",
              "      <td>comment va le chien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4979</th>\n",
              "      <td>i already ate</td>\n",
              "      <td>jai déjà mangé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4980</th>\n",
              "      <td>i always lose</td>\n",
              "      <td>je perds toujours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4981</th>\n",
              "      <td>i always walk</td>\n",
              "      <td>je vais toujours à pied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4982</th>\n",
              "      <td>i always walk</td>\n",
              "      <td>je marche toujours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4983</th>\n",
              "      <td>i am american</td>\n",
              "      <td>je suis américain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4984</th>\n",
              "      <td>i am american</td>\n",
              "      <td>je suis américaine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4985</th>\n",
              "      <td>i am japanese</td>\n",
              "      <td>je suis japonais</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4986</th>\n",
              "      <td>i am a muslim</td>\n",
              "      <td>je suis musulman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4987</th>\n",
              "      <td>i am a muslim</td>\n",
              "      <td>je suis musulmane</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4988</th>\n",
              "      <td>i am a muslim</td>\n",
              "      <td>je suis musulman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4989</th>\n",
              "      <td>i am a runner</td>\n",
              "      <td>je suis un coureur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>i am all ears</td>\n",
              "      <td>je suis tout ouïe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>i am diabetic</td>\n",
              "      <td>je suis diabétique</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>i am divorced</td>\n",
              "      <td>je suis divorcé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>i am divorced</td>\n",
              "      <td>je suis divorcée</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>i am in paris</td>\n",
              "      <td>je suis à paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>i am new here</td>\n",
              "      <td>je suis nouveau ici</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>i am new here</td>\n",
              "      <td>je suis nouveau ici</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>i am not deaf</td>\n",
              "      <td>je ne suis pas sourd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>i am so sorry</td>\n",
              "      <td>je suis tellement désolé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>i am so sorry</td>\n",
              "      <td>je suis tellement désolée</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 en                          fr\n",
              "0                go                         va \n",
              "1                hi                      salut \n",
              "2               run                      cours \n",
              "3               run                     courez \n",
              "4               wow                   ça alors \n",
              "5              fire                     au feu \n",
              "6              help                    à laide \n",
              "7              jump                       saute\n",
              "8              stop                  ça suffit \n",
              "9              stop                       stop \n",
              "10             stop                  arrêtetoi \n",
              "11             wait                    attends \n",
              "12             wait                   attendez \n",
              "13            go on                    poursuis\n",
              "14            go on                   continuez\n",
              "15            go on                  poursuivez\n",
              "16            hello                    bonjour \n",
              "17            hello                      salut \n",
              "18            i see                je comprends\n",
              "19            i try                     jessaye\n",
              "20            i won                  jai gagné \n",
              "21            i won             je lai emporté \n",
              "22            oh no                     oh non \n",
              "23           attack                    attaque \n",
              "24           attack                   attaquez \n",
              "25           cheers                      santé \n",
              "26           cheers              à votre santé \n",
              "27           cheers                      merci \n",
              "28           cheers                 tchintchin \n",
              "29           get up                     lèvetoi\n",
              "...             ...                         ...\n",
              "4970  how can i pay        comment puisje payer\n",
              "4971  how can it be          comment se peutil \n",
              "4972  how can it be     comment cela se peutil \n",
              "4973  how do i look          de quoi aije lair \n",
              "4974  how old is he              quel âge atil \n",
              "4975  how thrilling        comme cest excitant \n",
              "4976  how thrilling       comme cest palpitant \n",
              "4977  how was class       comment était lécole \n",
              "4978   hows the dog        comment va le chien \n",
              "4979  i already ate              jai déjà mangé\n",
              "4980  i always lose           je perds toujours\n",
              "4981  i always walk     je vais toujours à pied\n",
              "4982  i always walk          je marche toujours\n",
              "4983  i am american           je suis américain\n",
              "4984  i am american          je suis américaine\n",
              "4985  i am japanese            je suis japonais\n",
              "4986  i am a muslim            je suis musulman\n",
              "4987  i am a muslim           je suis musulmane\n",
              "4988  i am a muslim            je suis musulman\n",
              "4989  i am a runner          je suis un coureur\n",
              "4990  i am all ears           je suis tout ouïe\n",
              "4991  i am diabetic          je suis diabétique\n",
              "4992  i am divorced             je suis divorcé\n",
              "4993  i am divorced            je suis divorcée\n",
              "4994  i am in paris             je suis à paris\n",
              "4995  i am new here         je suis nouveau ici\n",
              "4996  i am new here         je suis nouveau ici\n",
              "4997  i am not deaf        je ne suis pas sourd\n",
              "4998  i am so sorry   je suis tellement désolé \n",
              "4999  i am so sorry  je suis tellement désolée \n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "whNZrPX5imo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Appending SOS and EOS to sentences\n",
        "append= lambda s: 'SOS_ '+ s + ' _EOS'\n",
        "data= data.applymap(append)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OP-_k11AjgtV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#Create word dictionaries\n",
        "en_words= dict()\n",
        "fr_words= dict()\n",
        "\n",
        "def add_en_word(sent):\n",
        "  for i in sent.split():\n",
        "    if i in en_words:\n",
        "      en_words[i]= en_words[i] + 1\n",
        "    else:\n",
        "      en_words[i]= 1\n",
        "\n",
        "def add_fr_word(sent):\n",
        "  for i in sent.split():\n",
        "    if i in fr_words:\n",
        "      fr_words[i]= fr_words[i] + 1\n",
        "    else:\n",
        "      fr_words[i]= 1\n",
        "\n",
        "data.iloc[:, 0].apply(add_en_word)\n",
        "data.iloc[:, 1].apply(add_fr_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tueiQZqf4AQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A list of tuples sorted according to the values\n",
        "sorted_en_words = sorted(en_words.items(), key=operator.itemgetter(1))\n",
        "sorted_fr_words = sorted(fr_words.items(), key=operator.itemgetter(1))\n",
        "\n",
        "en_words= dict(sorted_en_words)\n",
        "fr_words= dict(sorted_fr_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpOc0uWjpZ8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_en= 0\n",
        "max_fr= 0\n",
        "def find_max_length_en(sent):\n",
        "  global max_en\n",
        "  if len(sent.split()) > max_en:\n",
        "    max_en= len(sent.split())\n",
        "    \n",
        "def find_max_length_fr(sent):\n",
        "  global max_fr\n",
        "  if len(sent.split()) > max_fr:\n",
        "    max_fr= len(sent.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UHczxPI5yMg5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "data.iloc[:, 0].apply(find_max_length_en)\n",
        "data.iloc[:, 1].apply(find_max_length_fr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "doG7MyABzXIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f0b5778-83d4-4b37-b5cf-4eedb4308d0c"
      },
      "cell_type": "code",
      "source": [
        "num_samples= data.shape[0]\n",
        "num_samples"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "Iz_nYexDgUV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_words = sorted(list(en_words))\n",
        "target_words = sorted(list(fr_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N826L9HvHEng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef25bdea-fee6-41d8-d57e-8410fdaaa897"
      },
      "cell_type": "code",
      "source": [
        "len(target_words)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "OvSLnX7ngp7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en_token_to_int = dict()\n",
        "en_int_to_token = dict()\n",
        "\n",
        "fr_token_to_int = dict()\n",
        "fr_int_to_token = dict()\n",
        "\n",
        "for i,token in enumerate(input_words):\n",
        "    en_token_to_int[token] = i\n",
        "    en_int_to_token[i]     = token\n",
        "\n",
        "for i,token in enumerate(target_words):\n",
        "    fr_token_to_int[token] = i\n",
        "    fr_int_to_token[i]     = token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tR0mQ5tZhNH8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.zeros((num_samples, max_en), dtype='float32')\n",
        "decoder_input_data = np.zeros((num_samples, max_fr), dtype='float32')\n",
        "decoder_target_data = np.zeros((num_samples, max_fr, len(target_words)), dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hh095fDTlNxf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(data.shape[0]):\n",
        "  en_sent, fr_sent= data['en'].iloc[i], data['fr'].iloc[i]\n",
        "  \n",
        "  for t, word in enumerate(en_sent.split()):\n",
        "    encoder_input_data[i, t] = en_token_to_int[word]\n",
        "      \n",
        "  for t, word in enumerate(fr_sent.split()):\n",
        "    decoder_input_data[i, t] = fr_token_to_int[word]\n",
        "    if t > 0:\n",
        "      decoder_target_data[i, t - 1, fr_token_to_int[word]] = 1. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgWSP5XHz1vd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE= 300   # Length of the vector that we willl get from the embedding layer\n",
        "UNITS         = 1024  # Hidden layers dimension \n",
        "DROPOUT       = 0.2   # Rate of the dropout layers\n",
        "BATCH_SIZE    = 50    # Batch size\n",
        "EPOCHS        = 30    # Number of epochs\n",
        "\n",
        "encoder_input = Input(shape=(max_en,))\n",
        "\n",
        "encoder_embedding = Embedding(input_dim = len(input_words), output_dim = EMBEDDING_SIZE)(encoder_input)\n",
        "encoder_dropout   = (TimeDistributed(Dropout(rate = DROPOUT)))(encoder_embedding)\n",
        "encoder_LSTM      = CuDNNLSTM(UNITS, return_sequences=True)(encoder_dropout)\n",
        "\n",
        "encoder_LSTM2_layer = CuDNNLSTM(UNITS, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM2_layer(encoder_LSTM)\n",
        "\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkGgPddhMYDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_input = Input(shape=(max_fr,))\n",
        "\n",
        "# Hidden layers of the decoder :\n",
        "decoder_embedding_layer = Embedding(input_dim = len(target_words), output_dim = EMBEDDING_SIZE)\n",
        "decoder_embedding = decoder_embedding_layer(decoder_input)\n",
        "\n",
        "decoder_dropout_layer = (TimeDistributed(Dropout(rate = DROPOUT)))\n",
        "decoder_dropout = decoder_dropout_layer(decoder_embedding)\n",
        "\n",
        "decoder_LSTM_layer = CuDNNLSTM(UNITS, return_sequences=True)\n",
        "decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state = encoder_states)\n",
        "\n",
        "decoder_LSTM_2_layer = CuDNNLSTM(UNITS, return_sequences=True, return_state=True)\n",
        "decoder_LSTM_2,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\n",
        "\n",
        "# Output layer of the decoder :\n",
        "decoder_dense = Dense(len(target_words), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_LSTM_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JCjPJJDO921",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "e8b9a538-7311-4f3b-9140-7c3fc0515f6f"
      },
      "cell_type": "code",
      "source": [
        "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
        "model.summary()\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 6, 300)       374400      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 12)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 6, 300)       0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 12, 300)      826500      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)        (None, 6, 1024)      5431296     time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 12, 300)      0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_10 (CuDNNLSTM)       [(None, 1024), (None 8396800     cu_dnnlstm_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_11 (CuDNNLSTM)       (None, 12, 1024)     5431296     time_distributed_6[0][0]         \n",
            "                                                                 cu_dnnlstm_10[0][1]              \n",
            "                                                                 cu_dnnlstm_10[0][2]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)       [(None, 12, 1024), ( 8396800     cu_dnnlstm_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 12, 2755)     2823875     cu_dnnlstm_12[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 31,680,967\n",
            "Trainable params: 31,680,967\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMvGmlAVPH3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1076
        },
        "outputId": "fbbfb847-7bc3-4cb5-b5ce-c872eef56f58"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "5000/5000 [==============================] - 14s 3ms/step - loss: 1.4753\n",
            "Epoch 2/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 1.2553\n",
            "Epoch 3/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 1.1190\n",
            "Epoch 4/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 1.0097\n",
            "Epoch 5/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.9162\n",
            "Epoch 6/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.8370\n",
            "Epoch 7/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.7684\n",
            "Epoch 8/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.7033\n",
            "Epoch 9/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.6472\n",
            "Epoch 10/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.5948\n",
            "Epoch 11/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.5485\n",
            "Epoch 12/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.5061\n",
            "Epoch 13/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.4699\n",
            "Epoch 14/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.4344\n",
            "Epoch 15/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.4032\n",
            "Epoch 16/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.3749\n",
            "Epoch 17/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.3510\n",
            "Epoch 18/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.3270\n",
            "Epoch 19/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.3074\n",
            "Epoch 20/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2901\n",
            "Epoch 21/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2744\n",
            "Epoch 22/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2596\n",
            "Epoch 23/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2466\n",
            "Epoch 24/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2350\n",
            "Epoch 25/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2255\n",
            "Epoch 26/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2139\n",
            "Epoch 27/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.2060\n",
            "Epoch 28/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.1987\n",
            "Epoch 29/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.1928\n",
            "Epoch 30/30\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 0.1840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38d2305ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "3e9vDI4US128",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}